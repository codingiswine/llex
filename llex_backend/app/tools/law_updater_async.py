#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLeX â€” Production-Grade Async DRF Law Updater
================================================================
ì™„ì „ ë¹„ë™ê¸° ë²•ë ¹ ìµœì‹ í™” ì‹œìŠ¤í…œ (10ëª… ë™ì‹œ ì„œë¹„ìŠ¤ ëŒ€ì‘)

ì£¼ìš” ê¸°ëŠ¥:
- âœ… ì™„ì „ ë¹„ë™ê¸° ì•„í‚¤í…ì²˜ (asyncio + aiohttp + asyncpg)
- âœ… ë™ì‹œì„± ì œì–´ (Semaphoreë¡œ API í˜¸ì¶œ ì œí•œ)
- âœ… ìë™ ì¬ì‹œë„ ë¡œì§ (exponential backoff)
- âœ… ì§„í–‰ ìƒí™© í‘œì‹œ (rich progress bar)
- âœ… ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…
- âœ… íŠ¸ëœì­ì…˜ ê´€ë¦¬
- âœ… ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

ì‚¬ìš©ë²•:
    python law_updater_async.py --all
    python law_updater_async.py --law "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™"

ìŠ¤ì¼€ì¤„ë§ (í¬ë¡ ):
    0 3 * * * cd /app && python app/tools/law_updater_async.py --all >> /var/log/law_updater.log 2>&1
"""

import os
import re
import sys
import json
import argparse
import uuid
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime
from contextlib import asynccontextmanager

import aiohttp
from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine
from sqlalchemy import text
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels
from openai import AsyncOpenAI

# Rich for beautiful progress bars
try:
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("âš ï¸  pip install rich ê¶Œì¥ (ì§„í–‰ ìƒí™© í‘œì‹œ)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(os.path.abspath(os.path.join(BASE_DIR, "..", "..")), ".env")
load_dotenv(ENV_PATH) if os.path.exists(ENV_PATH) else load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DB_USER = os.getenv("DB_USER", "daniel")
DB_PASS = os.getenv("DB_PASS", "")
DB_HOST = os.getenv("DB_HOST", "postgres")
DB_PORT = int(os.getenv("DB_PORT", 5432))
DB_NAME = os.getenv("DB_NAME", "llex")
QDRANT_HOST = os.getenv("QDRANT_HOST", "qdrant")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
LAW_OC_ID = os.getenv("LAW_OC_ID", "drsgh1")

EMBED_MODEL = "text-embedding-3-large"
EMBED_DIM = 3072
COLLECTION = "laws"

BASE_URL = "https://www.law.go.kr/DRF/lawService.do"
LAW_ID_MAP: Dict[str, str] = {
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•": "001766",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ë ¹": "003786",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ê·œì¹™": "007364",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™": "007363",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•": "009640",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ë ¹": "009708",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ê·œì¹™": "009717",
    "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ ": "013993",
    "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ ì‹œí–‰ë ¹": "014159",
}

# Concurrency settings
MAX_CONCURRENT_REQUESTS = 3  # ë™ì‹œ HTTP ìš”ì²­ ìˆ˜
MAX_CONCURRENT_EMBEDDINGS = 5  # ë™ì‹œ ì„ë² ë”© ìƒì„± ìˆ˜
BATCH_SIZE = 100  # Qdrant ë°°ì¹˜ í¬ê¸°
MAX_RETRIES = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

console = Console() if RICH_AVAILABLE else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def normalize_law_name(name: str) -> str:
    """ë²•ë ¹ëª… ì •ê·œí™”"""
    import unicodedata
    name = unicodedata.normalize("NFC", name or "")
    name = re.sub(r"[\sÂ·]", "", name)
    return name.strip()


def normalize_article(article: str) -> str:
    """ì¡°ë¬¸ë²ˆí˜¸ ì •ê·œí™” (ìˆ«ìë§Œ)"""
    return re.sub(r"[^\d]", "", article or "")


def clean_text(text: str) -> str:
    """
    ìœ ë‹ˆì½”ë“œ ë¬¸ì œ ë¬¸ì ì œê±° ë° ì •ì œ
    - Surrogate pair ì œê±°
    - ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (NFKC)
    - ì œì–´ ë¬¸ì ì œê±° (ì¤„ë°”ê¿ˆ/íƒ­ ì œì™¸)
    """
    if not text:
        return ""
    
    import unicodedata
    
    # 1. Surrogate pair ë° ì¸ì½”ë”© ë¶ˆê°€ëŠ¥í•œ ë¬¸ì ì œê±°
    text = text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')
    
    # 2. ìœ ë‹ˆì½”ë“œ ì •ê·œí™” (í˜¸í™˜ì„± ë¶„í•´ í›„ ì¬ê²°í•©)
    text = unicodedata.normalize('NFKC', text)
    
    # 3. ì œì–´ ë¬¸ì ì œê±° (ì¤„ë°”ê¿ˆ, íƒ­ì€ ìœ ì§€)
    text = ''.join(
        char for char in text 
        if char in ('\n', '\t') or not unicodedata.category(char).startswith('C')
    )
    
    return text.strip()


def deep_extract_text(value) -> List[str]:
    """DRF JSONì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    out = []
    if isinstance(value, list):
        for v in value:
            out.extend(deep_extract_text(v))
    elif isinstance(value, dict):
        for k, v in value.items():
            if k in ["ì¡°ë¬¸ë‚´ìš©", "ì¡°ë¬¸ë‹¨ìœ„", "í•­ë‚´ìš©", "í˜¸ë‚´ìš©", "ì „ë¬¸", "#text", "content"]:
                out.extend(deep_extract_text(v))
            else:
                out.extend(deep_extract_text(v))
    elif isinstance(value, str):
        t = value.strip()
        if t:
            out.append(t)
    return out


def extract_article_payloads(law_name: str, drf_json: dict) -> List[dict]:
    """DRF JSON â†’ ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ ë³€í™˜"""
    articles = drf_json.get("ë²•ë ¹", {}).get("ì¡°ë¬¸", {})
    if isinstance(articles, dict):
        articles = articles.get("ì¡°ë¬¸ë‹¨ìœ„", [articles])

    payloads = []
    for a in articles or []:
        if a.get("ì¡°ë¬¸ì—¬ë¶€") != "ì¡°ë¬¸":
            continue  # í¸/ì¥ ì œëª© ì œì™¸

        art_no = normalize_article(str(a.get("ì¡°ë¬¸ë²ˆí˜¸", "")))
        if not art_no:
            continue

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text_candidates = []
        if a.get("ì¡°ë¬¸ë‚´ìš©"):
            text_candidates.extend(deep_extract_text(a.get("ì¡°ë¬¸ë‚´ìš©")))
        if a.get("í•­"):
            text_candidates.extend(deep_extract_text(a.get("í•­")))
        if a.get("ì¡°ë¬¸ë‹¨ìœ„"):
            text_candidates.extend(deep_extract_text(a.get("ì¡°ë¬¸ë‹¨ìœ„")))

        full_text = "\n".join([t for t in text_candidates if t]).strip()
        if not full_text:
            title = a.get("ì¡°ë¬¸ì œëª©") or ""
            body = a.get("ì¡°ë¬¸ë‚´ìš©") or ""
            body_str = " ".join(deep_extract_text(body)) if body else ""
            full_text = (f"{title} {body_str}").strip()

        # ì‹œí–‰ì¼ì
        enf = a.get("ì¡°ë¬¸ì‹œí–‰ì¼ì") or drf_json.get("ë²•ë ¹", {}).get("ì‹œí–‰ì¼ì") or drf_json.get("ë²•ë ¹", {}).get("ì‹œí–‰ì¼")
        if isinstance(enf, list):
            enf = enf[-1]
        if isinstance(enf, dict):
            enf = enf.get("@ì‹œí–‰ì¼ì") or enf.get("#text")
        enforcement_date = (str(enf).strip() if enf else None) or ""

        if enforcement_date:
            enforcement_date = enforcement_date[:10]
            # DATE íƒ€ì…ìœ¼ë¡œ ë³€í™˜: "20251001" â†’ datetime.date ê°ì²´
            try:
                if len(enforcement_date) == 8 and enforcement_date.isdigit():
                    # YYYYMMDD â†’ date ê°ì²´
                    enforcement_date = datetime.strptime(enforcement_date, "%Y%m%d").date()
                elif len(enforcement_date) == 10 and enforcement_date[4] == '-':
                    # YYYY-MM-DD â†’ date ê°ì²´
                    enforcement_date = datetime.strptime(enforcement_date, "%Y-%m-%d").date()
                else:
                    enforcement_date = None
            except (ValueError, AttributeError):
                enforcement_date = None  # ì˜ëª»ëœ í˜•ì‹ì€ NULL

        if full_text:
            payloads.append({
                "chunk_id": str(uuid.uuid4()),
                "law_name": law_name,
                "law_name_norm": normalize_law_name(law_name),
                "article_number_norm": art_no,
                "text": clean_text(full_text),
                "enforcement_date": enforcement_date,
            })
    return payloads


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class AsyncLawUpdater:
    """ì™„ì „ ë¹„ë™ê¸° ë²•ë ¹ ì—…ë°ì´í„°"""

    def __init__(self):
        self.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self.engine: Optional[AsyncEngine] = None
        self.qdrant: Optional[QdrantClient] = None
        self.session: Optional[aiohttp.ClientSession] = None

        # Semaphores for concurrency control
        self.http_semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
        self.embed_semaphore = asyncio.Semaphore(MAX_CONCURRENT_EMBEDDINGS)

    async def __aenter__(self):
        """Async context manager entry"""
        await self.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        await self.cleanup()

    async def initialize(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not OPENAI_API_KEY:
            raise RuntimeError("OPENAI_API_KEY missing in environment")

        # AsyncEngine (asyncpg ì‚¬ìš©)
        db_url = f"postgresql+asyncpg://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
        self.engine = create_async_engine(
            db_url,
            pool_size=10,
            max_overflow=20,
            pool_pre_ping=True,
            echo=False
        )

        # Qdrant (ë™ê¸° í´ë¼ì´ì–¸íŠ¸ - ë‚´ë¶€ì ìœ¼ë¡œ ë¹„ë™ê¸° ì‚¬ìš©)
        self.qdrant = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=120)

        # aiohttp session
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)

        # ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
        await self.ensure_pg_schema()
        await asyncio.to_thread(self.ensure_qdrant_schema)

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.session:
            await self.session.close()
        if self.engine:
            await self.engine.dispose()

    async def ensure_pg_schema(self):
        """PostgreSQL í…Œì´ë¸” ìƒì„±"""
        # AsyncPGëŠ” prepared statementì—ì„œ ì—¬ëŸ¬ ëª…ë ¹ì„ ë™ì‹œ ì‹¤í–‰ ë¶ˆê°€ â†’ ë¶„ë¦¬ ì‹¤í–‰
        async with self.engine.begin() as conn:
            await conn.execute(text("""
                CREATE TABLE IF NOT EXISTS law_chunks (
                    id SERIAL PRIMARY KEY,
                    chunk_id TEXT UNIQUE,
                    law_name TEXT NOT NULL,
                    law_name_norm TEXT NOT NULL,
                    article_number_norm TEXT NOT NULL,
                    text TEXT NOT NULL,
                    enforcement_date DATE,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            await conn.execute(text("""
                CREATE UNIQUE INDEX IF NOT EXISTS idx_law_chunks_unique
                    ON law_chunks (law_name_norm, article_number_norm)
            """))
            await conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_law_chunks_law_name
                    ON law_chunks (law_name_norm)
            """))

    def ensure_qdrant_schema(self):
        """Qdrant ì»¬ë ‰ì…˜ ìƒì„± (ë™ê¸°)"""
        try:
            self.qdrant.get_collection(COLLECTION)
        except Exception:
            self.qdrant.recreate_collection(
                collection_name=COLLECTION,
                vectors_config=qmodels.VectorParams(
                    size=EMBED_DIM,
                    distance=qmodels.Distance.COSINE
                ),
            )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HTTP ìš”ì²­ (aiohttp + ì¬ì‹œë„)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def fetch_drf_json_with_retry(self, law_name: str) -> dict:
        """ë²•ì œì²˜ DRF API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§)"""
        law_id = LAW_ID_MAP.get(law_name, law_name)
        params = {
            "OC": LAW_OC_ID,
            "target": "law",
            "ID": law_id,
            "type": "JSON"
        }

        for attempt in range(MAX_RETRIES):
            try:
                async with self.http_semaphore:
                    async with self.session.get(BASE_URL, params=params) as resp:
                        resp.raise_for_status()
                        return await resp.json()
            except Exception as e:
                if attempt == MAX_RETRIES - 1:
                    raise
                wait_time = 2 ** attempt  # Exponential backoff
                if console:
                    console.print(f"âš ï¸  [{law_name}] ì¬ì‹œë„ {attempt + 1}/{MAX_RETRIES} (ëŒ€ê¸°: {wait_time}ì´ˆ)")
                await asyncio.sleep(wait_time)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PostgreSQL ì—…ì„œíŠ¸ (ë¹„ë™ê¸°)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def upsert_pg(self, rows: List[dict]):
        """PostgreSQL ë°°ì¹˜ upsert"""
        if not rows:
            return

        sql = text("""
            INSERT INTO law_chunks (
                chunk_id, law_name, law_name_norm, article_number_norm, text, enforcement_date
            )
            VALUES (
                :chunk_id, :law_name, :law_name_norm, :article_number_norm, :text, :enforcement_date
            )
            ON CONFLICT (law_name_norm, article_number_norm)
            DO UPDATE SET
                text = EXCLUDED.text,
                enforcement_date = EXCLUDED.enforcement_date,
                updated_at = CURRENT_TIMESTAMP;
        """)

        async with self.engine.begin() as conn:
            await conn.execute(sql, rows)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Qdrant ì—…ì„œíŠ¸ (ë¹„ë™ê¸° ì„ë² ë”©)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def create_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„± (ë™ì‹œì„± ì œì–´)"""
        # í…ìŠ¤íŠ¸ ì •ì œ (ìœ ë‹ˆì½”ë“œ ë¬¸ì œ ë¬¸ì ì œê±°)
        cleaned_texts = [clean_text(text) for text in texts]
        
        async with self.embed_semaphore:
            response = await self.openai_client.embeddings.create(
                model=EMBED_MODEL,
                input=cleaned_texts
            )
            return [item.embedding for item in response.data]

    async def upsert_qdrant(self, rows: List[dict], progress_callback=None):
        """Qdrant ë°°ì¹˜ ì—…ë¡œë“œ (ë¹„ë™ê¸° ì„ë² ë”©)"""
        if not rows:
            return

        for i in range(0, len(rows), BATCH_SIZE):
            batch = rows[i:i + BATCH_SIZE]

            # ì„ë² ë”© ìƒì„± (ë¹„ë™ê¸°)
            texts = [r["text"] for r in batch]
            vectors = await self.create_embeddings_batch(texts)

            # Qdrant í¬ì¸íŠ¸ ìƒì„±
            points = []
            for r, vec in zip(batch, vectors):
                # ê³ ìœ  ID ìƒì„± (ë²•ë ¹ëª… í•´ì‹œ + ì¡°ë¬¸ë²ˆí˜¸)
                pid = int(f"{abs(hash(r['law_name_norm'])) % 10_000}{r['article_number_norm']:0>4}")
                payload = {
                    "law_name": r["law_name"],
                    "law_name_norm": r["law_name_norm"],
                    "article_number_norm": r["article_number_norm"],
                    "text": r["text"],
                    "enforcement_date": r["enforcement_date"],
                }
                points.append(qmodels.PointStruct(id=pid, vector=vec, payload=payload))

            # Qdrant ì—…ë¡œë“œ (ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰)
            await asyncio.to_thread(
                self.qdrant.upsert,
                collection_name=COLLECTION,
                points=points
            )

            if progress_callback:
                progress_callback(len(batch))

            # ê³¼ë¶€í•˜ ë°©ì§€
            await asyncio.sleep(0.2)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë²•ë ¹ ì—…ë°ì´íŠ¸ ë¡œì§
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def update_one_law(self, law_name: str) -> int:
        """ë‹¨ì¼ ë²•ë ¹ ì—…ë°ì´íŠ¸"""
        try:
            if console:
                console.print(f"\nğŸ”„ [{law_name}] DRF API í˜¸ì¶œ ì¤‘...")

            # 1. DRF JSON ê°€ì ¸ì˜¤ê¸°
            drf_json = await self.fetch_drf_json_with_retry(law_name)

            # 2. ì¡°ë¬¸ ì¶”ì¶œ
            rows = extract_article_payloads(law_name, drf_json)
            if not rows:
                if console:
                    console.print(f"âš ï¸  [{law_name}] ì¶”ì¶œëœ ì¡°ë¬¸ ì—†ìŒ", style="yellow")
                return 0

            if console:
                console.print(f"ğŸ“ [{law_name}] {len(rows)}ê°œ ì¡°ë¬¸ ì¶”ì¶œ ì™„ë£Œ")

            # 3. PostgreSQL ì—…ë°ì´íŠ¸
            await self.upsert_pg(rows)
            if console:
                console.print(f"âœ… [{law_name}] PostgreSQL ì €ì¥ ì™„ë£Œ")

            # 4. Qdrant ì—…ë°ì´íŠ¸ (ì„ë² ë”© ìƒì„±)
            if console:
                console.print(f"ğŸ§  [{law_name}] ì„ë² ë”© ìƒì„± ë° Qdrant ì—…ë¡œë“œ ì¤‘...")

            uploaded = 0
            def update_progress(count):
                nonlocal uploaded
                uploaded += count

            await self.upsert_qdrant(rows, progress_callback=update_progress)

            if console:
                console.print(f"âœ… [{law_name}] ì™„ë£Œ: {len(rows)}ê°œ ì¡°ë¬¸ ë™ê¸°í™”", style="green bold")

            return len(rows)

        except Exception as e:
            if console:
                console.print(f"âŒ [{law_name}] ì‹¤íŒ¨: {e}", style="red bold")
            else:
                print(f"âŒ [{law_name}] ì‹¤íŒ¨: {e}")
            return 0

    async def update_all(self):
        """ëª¨ë“  ë²•ë ¹ ì—…ë°ì´íŠ¸ (ë™ì‹œ ì²˜ë¦¬)"""
        if console:
            console.print("\nğŸš€ ë²•ë ¹ ìµœì‹ í™” ì‹œì‘", style="cyan bold")
            console.print(f"ğŸ“š ëŒ€ìƒ: {len(LAW_ID_MAP)}ê°œ ë²•ë ¹\n")

        start_time = asyncio.get_event_loop().time()

        # ëª¨ë“  ë²•ë ¹ì„ ë™ì‹œì— ì²˜ë¦¬ (Semaphoreë¡œ ì œì–´)
        tasks = [self.update_one_law(law_name) for law_name in LAW_ID_MAP.keys()]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ì§‘ê³„
        total_articles = sum(r for r in results if isinstance(r, int))
        failed = sum(1 for r in results if isinstance(r, Exception))

        elapsed = asyncio.get_event_loop().time() - start_time

        if console:
            console.print(f"\nğŸ‰ ì™„ë£Œ!", style="green bold")
            console.print(f"ğŸ“Š ì´ {total_articles}ê°œ ì¡°ë¬¸ ë™ê¸°í™”")
            console.print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
            if failed > 0:
                console.print(f"âš ï¸  ì‹¤íŒ¨: {failed}ê°œ ë²•ë ¹", style="yellow")
        else:
            print(f"\nğŸ‰ ì™„ë£Œ: {total_articles}ê°œ ì¡°ë¬¸ ë™ê¸°í™” ({elapsed:.1f}ì´ˆ)")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="LLeX ë¹„ë™ê¸° ë²•ë ¹ ìµœì‹ í™” ë„êµ¬ (Production-Grade)"
    )
    parser.add_argument("--all", action="store_true", help="ëª¨ë“  ë²•ë ¹ ìµœì‹ í™”")
    parser.add_argument("--law", type=str, help="íŠ¹ì • ë²•ë ¹ëª…ë§Œ ìµœì‹ í™”")
    args = parser.parse_args()

    if not args.all and not args.law:
        parser.print_help()
        sys.exit(1)

    async with AsyncLawUpdater() as updater:
        if args.all:
            await updater.update_all()
        elif args.law:
            count = await updater.update_one_law(args.law)
            if console:
                console.print(f"\nâœ… {args.law}: {count}ê°œ ì¡°ë¬¸ ë™ê¸°í™” ì™„ë£Œ")


if __name__ == "__main__":
    asyncio.run(main())