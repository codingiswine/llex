#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
news_tool_v5.4_aiohttp (LLeX GPT-5 êµ¬ì¡° ì™„ì „ ë¹„ë™ê¸°íŒ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ì£¼ìš” ê°œì„ 
1ï¸âƒ£ requests â†’ aiohttp ì™„ì „ ë¹„ë™ê¸°í™”
2ï¸âƒ£ Google/Naver ë‰´ìŠ¤ ë™ì‹œ ìš”ì²­
3ï¸âƒ£ ToolChunk ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° êµ¬ì¡° ìœ ì§€
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

import os, re, html, datetime, asyncio, aiohttp
from typing import List, Dict, AsyncGenerator
from urllib.parse import urlparse
from app.config import settings
from core.stream import ToolChunk


NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
DEFAULT_UA = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0 Safari/537.36"
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ ê³µí†µ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def strip_tags(text: str) -> str:
    return html.unescape(re.sub(r"<[^>]+>", "", text or "")).strip()

def brand_from_link(link: str) -> str:
    try:
        host = urlparse(link).netloc.lower()
        if "naver" in host: return "NAVER"
        if "daum" in host: return "DAUM"
        if "google" in host: return "GOOGLE"
        if "yonhap" in host: return "YONHAP"
        parts = [p for p in host.split(".") if p not in {"www", "m", "co", "kr", "com", "net"}]
        return parts[-1].upper() if parts else "ì¶œì²˜ ë¯¸ìƒ"
    except:
        return "ì¶œì²˜ ë¯¸ìƒ"

def unique_preserve_order(items: List[Dict[str, str]]) -> List[Dict[str, str]]:
    seen, result = set(), []
    for it in items:
        title = it.get("title")
        if title and title not in seen:
            seen.add(title)
            result.append(it)
    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ Naver ë‰´ìŠ¤ (aiohttp)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def get_naver_news(session: aiohttp.ClientSession, query: str, max_results: int = 5) -> List[Dict[str, str]]:
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID or "",
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET or "",
        "User-Agent": DEFAULT_UA,
    }
    params = {"query": query, "display": max_results, "sort": "sim"}

    async with session.get(url, headers=headers, params=params, timeout=8) as res:
        data = await res.json()
        items = data.get("items", [])
        results = []
        for it in items:
            title = strip_tags(it.get("title", ""))
            desc = strip_tags(it.get("description", ""))
            link = it.get("originallink") or it.get("link", "")
            pub = it.get("pubDate", "")
            try:
                pub = datetime.datetime.strptime(pub, "%a, %d %b %Y %H:%M:%S %z").strftime("%Y-%m-%d")
            except Exception:
                pub = "ì •ë³´ ì—†ìŒ"
            results.append({
                "title": title,
                "description": desc,
                "link": link,
                "source": brand_from_link(link),
                "pubDate": pub,
            })
        return results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ Google ë‰´ìŠ¤ (aiohttp)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def get_google_news(session: aiohttp.ClientSession, query: str, max_results: int = 5) -> List[Dict[str, str]]:
    params = {"q": query, "tbm": "nws", "hl": "ko", "gl": "kr"}
    headers = {"User-Agent": DEFAULT_UA}

    async with session.get("https://www.google.com/search", params=params, headers=headers, timeout=8) as res:
        res_text = await res.text()

    blocks = re.findall(
        r'<a href="/url\?q=(.*?)&amp.*?<div[^>]*class="BNeawe vvjwJb[^"]*">(.*?)</div>.*?<div[^>]*class="BNeawe s3v9rd AP7Wnd">(.*?)</div>',
        res_text, re.S,
    )
    articles = []
    for link, title, source in blocks[:max_results]:
        clean_link = strip_tags(link)
        articles.append({
            "title": strip_tags(title),
            "link": clean_link,
            "source": brand_from_link(clean_link),
            "pubDate": "ì •ë³´ ì—†ìŒ",
            "description": "",
        })
    return articles


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§  GPT í”„ë¡¬í”„íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt(query: str, items: List[Dict[str, str]]) -> str:
    header = (
        f"'{query}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë¥¼ 3ê±´ ìš”ì•½í•˜ì„¸ìš”.\n"
        "ì¶œë ¥ í˜•ì‹:\n"
        "1ï¸âƒ£ ì œëª©  \n"
        "ì¶œì²˜ : ë§¤ì²´ëª…(ë§í¬) Â· ë‚ ì§œ  \n"
        "ìš”ì•½ (2~3ì¤„, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´)\n"
        "---\n\n"
        "ì£¼ì˜:\n"
        "- ì œëª©ì€ êµµê²Œ(**ì œëª©**)\n"
        "- Markdown ë§í¬ëŠ” (ë§í¬) í˜•ì‹ìœ¼ë¡œ ìœ ì§€\n"
        "- ê° ë‰´ìŠ¤ëŠ” 3ì¤„ ì´í•˜\n"
    )
    context = "\n".join([
        f"- ì œëª©: {i['title']}\n  ë§¤ì²´: {i['source']}\n  ë‚ ì§œ: {i.get('pubDate','')}\n  ë§í¬: {i['link']}\n  ë‚´ìš©: {i.get('description','')}"
        for i in items
    ])
    return header + "\n[ê¸°ì‚¬ ë°ì´í„°]\n" + context


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸš€ ë©”ì¸ ì‹¤í–‰ (ë¹„ë™ê¸° Stream)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def run(plan) -> AsyncGenerator[ToolChunk, None]:
    query = plan.args.get("query", "")
    yield ToolChunk(type="status", payload=f"ğŸ—ï¸ '{query}' ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")

    async with aiohttp.ClientSession() as session:
        google_task = asyncio.create_task(get_google_news(session, query))
        naver_task = asyncio.create_task(get_naver_news(session, query))
        google, naver = await asyncio.gather(google_task, naver_task)

    items = unique_preserve_order(google + naver)
    if not items:
        yield ToolChunk(type="error", payload="âŒ ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    yield ToolChunk(type="status", payload=f"ğŸ§  GPTê°€ {len(items)}ê±´ ìš”ì•½ ì¤‘...")

    prompt = build_prompt(query, items)
    stream = await settings.openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        stream=True,
    )

    async for chunk in stream:
        delta = chunk.choices[0].delta.content
        if delta:
            yield ToolChunk(type="text", payload=delta)

    yield ToolChunk(
        type="source",
        payload=[{"title": i["title"], "link": i["link"], "source": i["source"]} for i in items[:5]],
    )
    yield ToolChunk(type="status", payload="âœ… ë‰´ìŠ¤ ìš”ì•½ ì™„ë£Œ")
