#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
websearch_tool.py (v3.1, Async Parallel)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ê°œì„  ìš”ì•½
1ï¸âƒ£ requests â†’ aiohttp (ì™„ì „ ë¹„ë™ê¸°í™”)
2ï¸âƒ£ Google + Naver ë‰´ìŠ¤/ë¸”ë¡œê·¸ ë³‘ë ¬ ì‹¤í–‰ (asyncio.gather)
3ï¸âƒ£ summarize_web() í˜¸ì¶œ ì‹œ ì™„ì „ async-safe
4ï¸âƒ£ ê²°ê³¼ êµ¬ì¡° ìœ ì§€ (summaries + raw_results)
"""

import aiohttp
import asyncio
from typing import List, Dict
try:
    from app.config import settings   # âœ… Docker ì‹¤í–‰ ì‹œ
except ModuleNotFoundError:
    from app.config import settings  # âœ… ë¡œì»¬ ì‹¤í–‰ ì‹œ



# --------------------------
# ğŸ” ë¹„ë™ê¸° Naver ê²€ìƒ‰
# --------------------------
async def naver_search(session, query: str, search_type: str = "news", display: int = 5) -> List[Dict]:
    url = f"https://openapi.naver.com/v1/search/{search_type}.json"
    headers = {
        "X-Naver-Client-Id": settings.NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": settings.NAVER_CLIENT_SECRET,
    }
    params = {"query": query, "display": display, "sort": "date"}

    try:
        async with session.get(url, headers=headers, params=params, timeout=10) as res:
            if res.status != 200:
                print(f"âš ï¸ Naver {search_type} HTTP {res.status}")
                return []
            data = await res.json()
            items = data.get("items", [])
            return [
                {
                    "title": i.get("title"),
                    "link": i.get("link"),
                    "snippet": i.get("description"),
                    "source": f"naver_{search_type}",
                }
                for i in items
            ]
    except Exception as e:
        print(f"âš ï¸ Naver {search_type} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


# --------------------------
# ğŸ” ë¹„ë™ê¸° Google ê²€ìƒ‰
# --------------------------
async def google_search(session, query: str, num: int = 5) -> List[Dict]:
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": settings.GOOGLE_SEARCH_API_KEY,
        "cx": settings.GOOGLE_SEARCH_ENGINE_ID,
        "q": f"{query} site:news.naver.com OR site:yna.co.kr OR site:kbs.co.kr OR site:sbs.co.kr OR site:mbc.co.kr OR site:chosun.com OR site:joongang.co.kr OR site:donga.com",
        "num": num,
    }
    try:
        async with session.get(url, params=params, timeout=10) as res:
            if res.status != 200:
                print(f"âš ï¸ Google HTTP {res.status}")
                return []
            data = await res.json()
            items = data.get("items", [])
            return [
                {
                    "title": i.get("title"),
                    "link": i.get("link"),
                    "snippet": i.get("snippet"),
                    "source": "google_news",
                }
                for i in items
            ]
    except Exception as e:
        print(f"âš ï¸ Google ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


# --------------------------
# ğŸŒ í†µí•© ì›¹ê²€ìƒ‰ (ë³‘ë ¬)
# --------------------------
async def get_web_results(query: str) -> List[Dict]:
    """Google + Naver ë‰´ìŠ¤/ë¸”ë¡œê·¸ ë¹„ë™ê¸° ë³‘ë ¬"""
    async with aiohttp.ClientSession() as session:
        naver_news, naver_blog, google_news = await asyncio.gather(
            naver_search(session, query, "news"),
            naver_search(session, query, "blog"),
            google_search(session, query),
        )
    all_results = naver_news + naver_blog + google_news

    # ì¤‘ë³µ ì œê±°
    seen, unique_results = set(), []
    for r in all_results:
        if r["link"] not in seen:
            unique_results.append(r)
            seen.add(r["link"])
    return unique_results


# --------------------------
# ğŸ§  GPT ìš”ì•½ (ë¹„ë™ê¸°)
# --------------------------
async def summarize_web(query: str, max_results: int = 8) -> Dict:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ GPTë¡œ ìš”ì•½ (ë¹„ë™ê¸°, ë²•ë ¹ ì œì™¸)"""
    if len(query) > 500:
        query = query[:500] + " ..."

    results = await get_web_results(query)
    results = results[:max_results]

    if not results:
        return {"summaries": "ğŸ“° ê´€ë ¨ ë‰´ìŠ¤/ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "raw_results": []}

    # ë‰´ìŠ¤/ë¸”ë¡œê·¸ êµ¬ë¶„
    context = "\n\n".join(
        [f"[{i+1}] {r['title']}\n{r['snippet']}\n{r['link']}" for i, r in enumerate(results)]
    )

    messages = [
        {"role": "system", "content": (
            "ë„ˆëŠ” í•œêµ­ ë‰´ìŠ¤Â·ë¸”ë¡œê·¸ ìš”ì•½ ì „ë¬¸ê°€ì•¼.\n"
            "ë²•ì¡°ë¬¸ ì–¸ê¸‰ ì—†ì´ í˜„ì‹¤ì ì¸ ë‰´ìŠ¤Â·ë¸”ë¡œê·¸ ìš”ì•½ë§Œ ì œì‹œí•´.\n"
            "[ë‰´ìŠ¤]\n1. ì œëª© / í•µì‹¬ ìš”ì•½\n[ë¸”ë¡œê·¸]\n1. ì‘ì„±ì / ì£¼ìš” ê´€ì  ìš”ì•½"
        )},
        {"role": "user", "content": f"ì§ˆë¬¸: {query}\n\nê²€ìƒ‰ ê²°ê³¼:\n{context}"}
    ]

    try:
        completion = await settings.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.4,
            max_tokens=700,
        )
        summary = completion.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ GPT ìš”ì•½ ì‹¤íŒ¨: {e}")
        summary = "ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return {"summaries": summary, "raw_results": results}


# --------------------------
# ğŸ§ª ë‹¨ë… í…ŒìŠ¤íŠ¸
# --------------------------
if __name__ == "__main__":
    async def _test():
        q = "ì†Œí™”ê¸° ì„¤ì¹˜ ê¸°ì¤€"
        result = await summarize_web(q)
        print("âœ… ìš”ì•½ ê²°ê³¼:\n", result["summaries"])
        print("\nğŸ§© ì›ë¬¸ ë§í¬:")
        for r in result["raw_results"]:
            print(f"- {r['title']} ({r['source']}) â†’ {r['link']}")

    asyncio.run(_test())
