#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
law_rag_tool_async_v6.11_direct_article_linked.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ì£¼ìš” ê°œì„ 
1ï¸âƒ£ "ë²•ë ¹ëª… + ì¡°ë¬¸ë²ˆí˜¸" ì§ˆì˜ ì‹œ ë‹¨ìˆœ í¬ë§· ì¶œë ¥
   â†’ ë²• ì„¤ëª… / ì¡°ë¬¸ ì „ë¬¸ / ë²•ë ¹ ì •ë³´(í•˜ì´í¼ë§í¬ í¬í•¨)
2ï¸âƒ£ ì‹œí–‰ì¼ìëŠ” DB ê°’ë§Œ í‘œì‹œ (GPT ìƒì„± ê¸ˆì§€)
3ï¸âƒ£ ì¶œì²˜ëŠ” [ë²•ë ¹ëª… ì œnì¡°](ë§í¬) í•˜ì´í¼ë§í¬ë¡œ í‘œì‹œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

import re, urllib.parse, aiohttp
from datetime import datetime
from typing import Optional, Dict
from sqlalchemy import text
from qdrant_client.http.models import FieldCondition, MatchValue, Filter
from core.stream import ToolChunk
from app.tools.websearch_tool import summarize_web
try:
    from app.config import settings   # âœ… Docker ì‹¤í–‰ ì‹œ
except ModuleNotFoundError:
    from app.config import settings  # âœ… ë¡œì»¬ ì‹¤í–‰ ì‹œ



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
qdrant = settings.qdrant_client
async_engine = settings.async_engine
COLLECTION = settings.QDRANT_COLLECTION_NAME


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_law_name(name: str) -> str:
    import unicodedata
    return re.sub(r"[\sÂ·]", "", unicodedata.normalize("NFC", name.strip()))

def normalize_article(article: str) -> str:
    return re.sub(r"[^\d]", "", article or "")

def detect_law_name(query: str) -> Optional[str]:
    """ì§ˆë¬¸ ë‚´ì—ì„œ ë²•ë ¹ëª… ìë™ ê°ì§€"""
    LAWS = [
        "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™", "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ê·œì¹™", "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ë ¹", "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•",
        "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ê·œì¹™", "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ë ¹", "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•",
        "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ ì‹œí–‰ë ¹", "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ "
    ]
    q = re.sub(r"\s+", "", query)
    for law in LAWS:
        if law in q:
            return normalize_law_name(law)
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•µì‹¬ ì‹¤í–‰ (Async)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def run(plan):
    query = plan.args.get("query", "")
    yield ToolChunk(type="status", payload="âš–ï¸ ë²•ë ¹ ê²€ìƒ‰ ì‹œì‘...")

    law_name = detect_law_name(query)
    article_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¡°", query)
    article_number = article_match.group(1) if article_match else ""

    is_direct_article_query = bool(law_name and article_number)

    # â‘  ë²•ë ¹ëª… ë¯¸ì¸ì‹ ì‹œ Web fallback
    if not law_name:
        yield ToolChunk(type="status", payload="âš ï¸ ë²•ë ¹ëª…ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ â†’ Web ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        web_result = await summarize_web(query)
        web_summary = web_result.get("summaries", "")
        resp = await settings.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": f"""
                ëŒ€í•œë¯¼êµ­ ë²•ë ¹ í•´ì„¤ ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•˜ì„¸ìš”.
                ì§ˆë¬¸: {query}
                ---
                {web_summary}
                ---
                ğŸ”¹ **ê²°ë¡ **
                ğŸ”¹ **ì„¤ì¹˜ ë˜ëŠ” ì ìš© ê¸°ì¤€**
                ğŸ”¹ **ë²•ì  ê·¼ê±°**
                ğŸ”¹ **ì¶œì²˜**
                """
            }],
            temperature=0.3,
        )
        answer = resp.choices[0].message.content.strip()
        yield ToolChunk(type="text", payload=answer)
        yield ToolChunk(type="status", payload="âœ… Web ë³´ì™„ ê²€ìƒ‰ ì™„ë£Œ")
        return

    # â‘¡ PostgreSQL ê²€ìƒ‰ (1ì°¨: ì •í™•í•œ ì¡°ë¬¸ ê²€ìƒ‰)
    text_val, enforcement_date = None, None
    search_law_norm = normalize_law_name(law_name)
    search_article_norm = normalize_article(article_number)

    try:
        async with async_engine.connect() as conn:
            result = await conn.execute(
                text("""
                    SELECT text, enforcement_date
                    FROM law_chunks
                    WHERE law_name_norm = :law AND article_number_norm = :num
                    LIMIT 1;
                """),
                {"law": search_law_norm, "num": search_article_norm}
            )
            row = result.fetchone()
            if row:
                text_val, enforcement_date = row
                yield ToolChunk(type="status", payload="âœ… [PostgreSQL] ì¡°ë¬¸ ë°œê²¬")
            else:
                yield ToolChunk(type="status", payload="ğŸ” [Qdrant] ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜...")
    except Exception as e:
        yield ToolChunk(type="status", payload=f"âš ï¸ [PostgreSQL] ì˜¤ë¥˜ â†’ Qdrant ê²€ìƒ‰")

    # â‘¢ Qdrant (2ì°¨: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰)
    if not text_val:
        yield ToolChunk(type="status", payload="ğŸ§  [Qdrant] ë²¡í„° ê²€ìƒ‰ ì¤‘...")
        try:
            emb = await settings.openai_client.embeddings.create(
                model="text-embedding-3-large",
                input=query
            )
            embedding = emb.data[0].embedding
            q_filter = Filter(
                must=[
                    FieldCondition(key="law_name_norm", match=MatchValue(value=search_law_norm)),
                    FieldCondition(key="article_number_norm", match=MatchValue(value=search_article_norm)),
                ]
            )
            results = await qdrant.search(
                COLLECTION,
                embedding,
                query_filter=q_filter,
                limit=1,
                with_payload=True
            )
            if results and results[0].score >= 0.7:
                best = results[0]
                text_val = best.payload.get("text", "")
                enforcement_date = best.payload.get("enforcement_date", "")
                yield ToolChunk(type="status", payload=f"âœ… [Qdrant] ìœ ì‚¬ë„ {best.score:.2f} ì¡°ë¬¸ ë°œê²¬")
        except Exception as e:
            yield ToolChunk(type="status", payload=f"âš ï¸ Qdrant ê²€ìƒ‰ ì‹¤íŒ¨")

    # â‘£ Web fallback (ëª¨ë“  ì¡°ë¬¸ ê²€ìƒ‰ ì‹¤íŒ¨)
    if not text_val or str(text_val).strip() == "":
        yield ToolChunk(type="status", payload="âš ï¸ ì¡°ë¬¸ ì—†ìŒ â†’ Web fallback ì‹¤í–‰")
        web_result = await summarize_web(query)
        web_summary = web_result.get("summaries", "")
        resp = await settings.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": f"""
                ì§ˆë¬¸: {query}
                ---
                {web_summary}
                ---
                ğŸ”¹ **ê²°ë¡ **
                ğŸ”¹ **ì„¤ì¹˜ ë˜ëŠ” ì ìš© ê¸°ì¤€**
                ğŸ”¹ **ë²•ì  ê·¼ê±°**
                ğŸ”¹ **ì¶œì²˜**
                """
            }],
            temperature=0.3,
        )
        answer = resp.choices[0].message.content.strip()
        yield ToolChunk(type="text", payload=answer)
        yield ToolChunk(type="status", payload="âœ… Web fallback ì™„ë£Œ")
        return

    # â‘¤ ì¡°ë¬¸ ë°œê²¬ ì‹œ GPT ìš”ì•½
    yield ToolChunk(type="status", payload="ğŸ§  GPT ìš”ì•½ ì¤‘...")

    # âœ… í¬ë§· ë¶„ê¸°
    if is_direct_article_query:
        prompt = f"""
        ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ë²•ë ¹ í•´ì„¤ ì „ë¬¸ê°€ì•¼.
        ì•„ë˜ ì¡°ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë²•ì˜ ì·¨ì§€ì™€ ëª©ì ë§Œ ì„¤ëª…í•´.
        âš ï¸ ì‹œí–‰ì¼ìë‚˜ ì¶œì²˜ë¥¼ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆ.

        ì¶œë ¥ í˜•ì‹:
        ğŸ”¹ **ë²• ì„¤ëª…**
        - ë²•ì˜ ì·¨ì§€ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½
        ğŸ“œ **ì¡°ë¬¸ ì „ë¬¸**
        - ì›ë¬¸ ê·¸ëŒ€ë¡œ í‘œì‹œ (ì¡°ë¬¸ ë‚´ ê°œì •ì¼ì€ ê·¸ëŒ€ë¡œ ë‘¬ë„ ë¨)
        ---
        [ì¡°ë¬¸ ì „ë¬¸]
        {text_val}
        """
    else:
        prompt = f"""
        ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ë²•ë ¹ í•´ì„¤ ì „ë¬¸ê°€ì•¼.
        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ì•„ë˜ ì¡°ë¬¸ì„ ì°¸ê³ í•´ ì‹¤ë¬´ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´.
        ---
        ğŸ”¹ **ê²°ë¡ **
        ğŸ”¹ **ì„¤ì¹˜ ë˜ëŠ” ì ìš© ê¸°ì¤€**
        ğŸ”¹ **ë²•ì  ê·¼ê±°**
        ğŸ”¹ **ì¶œì²˜**
        [ì¡°ë¬¸ ì „ë¬¸]
        {text_val}
        """

    try:
        # âœ… GPT í˜¸ì¶œì„ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë³€ê²½
        stream = await settings.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            stream=True,  # â† ì´ê²Œ í•µì‹¬!
        )
    
        summary_parts = []
        async for chunk in stream:
            delta = chunk.choices[0].delta.content
            if delta:
                summary_parts.append(delta)
                # âœ… ìŠ¤íŠ¸ë¦¬ë° ì¤‘ê°„ì—ë„ ë°”ë¡œ ì „ì†¡
                yield ToolChunk(type="text", payload=delta)
        
        # âœ… ìŠ¤íŠ¸ë¦¼ ëë‚˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
        summary = "".join(summary_parts).strip()
        law_url = f"https://www.law.go.kr/ë²•ë ¹/{urllib.parse.quote(law_name)}/ì œ{article_number}ì¡°"

        # âœ… ì¶œë ¥ í¬ë§· (Markdown í•˜ì´í¼ë§í¬ ì ìš©)
        if is_direct_article_query:
            # âš™ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ì´ë¯¸ ë³¸ë¬¸ì„ ë³´ëƒˆìœ¼ë¯€ë¡œ
            # ì—¬ê¸°ì„œëŠ” ë²•ë ¹ ì •ë³´(ì‹œí–‰ì¼ì, ì¶œì²˜)ë§Œ ì¶”ê°€ ì¶œë ¥
            footer = (
                f"\n\nğŸ“˜ **ë²•ë ¹ ì •ë³´**  \n"
                f"ì‹œí–‰ì¼ì: {enforcement_date or 'ì •ë³´ ì—†ìŒ'}  \n"
                f"ì¶œì²˜: [{law_name} ì œ{article_number}ì¡°]({law_url})"
            )
            yield ToolChunk(type="text", payload=footer)
        else:
            # ì¼ë°˜ ì§ˆë¬¸ì¼ ê²½ìš° ì „ì²´ ì¶œë ¥ í•„ìš”
            final_text = (
                f"{summary}\n\n"
                f"ğŸ“œ **ì¡°ë¬¸ ì „ë¬¸**\n{text_val}\n\n"
                f"**ì‹œí–‰ì¼ì:** {enforcement_date or 'ì •ë³´ ì—†ìŒ'}"
            )
            yield ToolChunk(type="text", payload=final_text)

        # âœ… ë§ˆì§€ë§‰ì— ì¶œì²˜ ì •ë³´ë§Œ ë³„ë„ë¡œ ì „ì†¡
        yield ToolChunk(type="source", payload={"law_url": law_url})

    except Exception as e:
        yield ToolChunk(type="error", payload=f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨: {e}")

    yield ToolChunk(type="status", payload="âœ… ë²•ë ¹ ê²€ìƒ‰ ì™„ë£Œ")

