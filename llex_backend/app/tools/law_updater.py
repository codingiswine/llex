#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLeX â€” DRF ë§¤ì¼ ìµœì‹ í™” & Postgres/Qdrant ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸
================================================================
ëª©ì 
- ë²•ì œì²˜ DRF(JSON)ì—ì„œ ì§€ì •ëœ ë²•ë ¹ë“¤ì„ ë§¤ì¼ ë°›ì•„ ìµœì‹  ì¡°ë¬¸ ë‹¨ìœ„ë¡œ ì •ê·œí™”
- PostgreSQL(law_chunks)ì™€ Qdrant(laws ì»¬ë ‰ì…˜)ì— Upsert(ë™ê¸°í™”)
- ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ: 'ì¡°ë¬¸ì—¬ë¶€=ì¡°ë¬¸' ë³¸ë¬¸ë§Œ ì €ì¥, í¸/ì¥ ì œëª©('ì „ë¬¸') í•„í„°ë§

ì‚¬ìš© ë°©ë²•(ìš”ì•½)
1) .env ì„¤ì •(ì•„ë˜ ìƒ˜í”Œ ì°¸ê³ )
2) python law_updater.py --all  # ëª¨ë“  ë²•ë ¹ ìµœì‹ í™”
3) (ê¶Œì¥) í¬ë¡ /launchd/pm2 ë“±ìœ¼ë¡œ ë§¤ì¼ 1íšŒ ìë™ ì‹¤í–‰

í•„ìˆ˜ .env í‚¤
- OPENAI_API_KEY
- DB_USER, DB_PASS, DB_HOST, DB_PORT, DB_NAME
- QDRANT_HOST, QDRANT_PORT
- LAW_OC_ID (ë²•ì œì²˜ DRF OC í‚¤)

í…Œì´ë¸” ìš”êµ¬ì‚¬í•­ (ìë™ ìƒì„±)
- law_chunks(law_name_norm, article_number_norm, text, enforcement_date)
  * (law_name_norm, article_number_norm) UNIQUE ì¸ë±ìŠ¤

Qdrant ìš”êµ¬ì‚¬í•­ (ìë™ ìƒì„±)
- ì»¬ë ‰ì…˜ëª…: laws
- vector size: OpenAI text-embedding-3-large(3072)

ìŠ¤ì¼€ì¤„ë§ ì˜ˆì‹œ
- í¬ë¡ :  ë§¤ì¼ ìƒˆë²½ 3ì‹œ â†’ 0 3 * * * /usr/bin/python3 /path/to/law_updater.py --all >> /var/log/llex_law_updater.log 2>&1

ì£¼ì˜
- DRF ì‘ë‹µ êµ¬ì¡°ê°€ ë²•ë ¹ë§ˆë‹¤ ë‹¤ë¥´ë¯€ë¡œ, ë³¸ë¬¸ ì¶”ì¶œì€ ë”¥ íŒŒì„œ ì‚¬ìš©(ì¡°ë¬¸/í•­/í˜¸ + #text/ì „ë¬¸ ëŒ€ì‘)
- ì €ì¥ ì‹œ ì¡°ë¬¸ë²ˆí˜¸ê°€ ë™ì¼í•˜ê³  'ì¡°ë¬¸ì—¬ë¶€=ì „ë¬¸'ì¸ í•­ëª©ì€ ê±´ë„ˆëœ€
"""

import os
import re
import sys
import json
import time
import argparse
import uuid
from typing import Dict, List, Optional
from datetime import datetime

import requests
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from qdrant_client import QdrantClient
from qdrant_client.http import models as qmodels
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(os.path.abspath(os.path.join(BASE_DIR, "..", "..")), ".env")
load_dotenv(ENV_PATH) if os.path.exists(ENV_PATH) else load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DB_USER = os.getenv("DB_USER", "linkcampus")
DB_PASS = os.getenv("DB_PASS", "")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = int(os.getenv("DB_PORT", 5432))
DB_NAME = os.getenv("DB_NAME", "law_chatbot")
QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
LAW_OC_ID = os.getenv("LAW_OC_ID", "drsgh1")

EMBED_MODEL = "text-embedding-3-large"
EMBED_DIM = 3072  # ëª¨ë¸ ì°¨ì›(2025-10 ê¸°ì¤€)
COLLECTION = "laws"

BASE_URL = "https://www.law.go.kr/DRF/lawService.do"
LAW_ID_MAP: Dict[str, str] = {
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•": "001766",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ë ¹": "003786",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ì‹œí–‰ê·œì¹™": "007364",
    "ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™": "007363",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•": "009640",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ë ¹": "009708",
    "ì¬ë‚œë°ì•ˆì „ê´€ë¦¬ê¸°ë³¸ë²•ì‹œí–‰ê·œì¹™": "009717",
    "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ ": "013993",
    "ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë“±ì—ê´€í•œë²•ë¥ ì‹œí–‰ë ¹": "014159",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def normalize_law_name(name: str) -> str:
    import unicodedata
    name = unicodedata.normalize("NFC", name or "")
    name = re.sub(r"[\sÂ·]", "", name)
    return name.strip()


def normalize_article(article: str) -> str:
    return re.sub(r"[^\d]", "", article or "")


def deep_extract_text(value) -> List[str]:
    """DRF JSONì˜ ëª¨ë“  ì¤‘ì²© êµ¬ì¡°ì—ì„œ ë¬¸ìì—´ì„ ìˆ˜ì§‘ (#text/ì „ë¬¸/ì¡°ë¬¸ë‚´ìš©/í•­ë‚´ìš©/í˜¸ë‚´ìš© í¬í•¨)."""
    out = []
    if isinstance(value, list):
        for v in value:
            out.extend(deep_extract_text(v))
    elif isinstance(value, dict):
        for k, v in value.items():
            if k in ["ì¡°ë¬¸ë‚´ìš©", "ì¡°ë¬¸ë‹¨ìœ„", "í•­ë‚´ìš©", "í˜¸ë‚´ìš©", "ì „ë¬¸", "#text", "content"]:
                out.extend(deep_extract_text(v))
            else:
                out.extend(deep_extract_text(v))
    elif isinstance(value, str):
        t = value.strip()
        if t:
            out.append(t)
    return out


def extract_article_payloads(law_name: str, drf_json: dict) -> List[dict]:
    """DRF JSON â†’ ì¡°ë¬¸(ë³¸ë¬¸) ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì¤€í™”.
    - 'ì¡°ë¬¸ì—¬ë¶€' == 'ì¡°ë¬¸' ì¸ í•­ëª©ë§Œ ëŒ€ìƒ
    - í…ìŠ¤íŠ¸: ì¡°ë¬¸ë‚´ìš© + í•­/í˜¸ê¹Œì§€ í†µí•©
    - ì¡°ë¬¸ë²ˆí˜¸ëŠ” ìˆ«ìë§Œ(article_number_norm)
    - ì‹œí–‰ì¼ì ì¶”ì¶œ(ê°€ëŠ¥ ì‹œ)
    """
    articles = drf_json.get("ë²•ë ¹", {}).get("ì¡°ë¬¸", {})
    if isinstance(articles, dict):
        articles = articles.get("ì¡°ë¬¸ë‹¨ìœ„", [articles])

    payloads = []
    for a in articles or []:
        if a.get("ì¡°ë¬¸ì—¬ë¶€") != "ì¡°ë¬¸":
            continue  # í¸/ì¥ ì œëª©('ì „ë¬¸') ì œì™¸

        art_no = normalize_article(str(a.get("ì¡°ë¬¸ë²ˆí˜¸", "")))
        if not art_no:
            continue

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text_candidates = []
        if a.get("ì¡°ë¬¸ë‚´ìš©"):
            text_candidates.extend(deep_extract_text(a.get("ì¡°ë¬¸ë‚´ìš©")))
        if a.get("í•­"):
            text_candidates.extend(deep_extract_text(a.get("í•­")))
        # ë³´ì •: ì¼ë¶€ ë²•ë ¹ì€ ì¡°ë¬¸ë‹¨ìœ„ ì•„ë˜ì— ë³¸ë¬¸ì´ ìˆëŠ” í˜•íƒœ
        if a.get("ì¡°ë¬¸ë‹¨ìœ„"):
            text_candidates.extend(deep_extract_text(a.get("ì¡°ë¬¸ë‹¨ìœ„")))

        full_text = "\n".join([t for t in text_candidates if t]).strip()
        if not full_text:
            # ìµœí›„ ë³´ì •: ì¡°ë¬¸ì œëª© + ì¡°ë¬¸ë‚´ìš© ë‹¨ì¼ ë¬¸ìì—´ ì¡°í•© ì‹œë„
            title = a.get("ì¡°ë¬¸ì œëª©") or ""
            body = a.get("ì¡°ë¬¸ë‚´ìš©") or ""
            body_str = " ".join(deep_extract_text(body)) if body else ""
            full_text = (f"{title} {body_str}").strip()

        # ì‹œí–‰ì¼ì
        enf = a.get("ì¡°ë¬¸ì‹œí–‰ì¼ì") or drf_json.get("ë²•ë ¹", {}).get("ì‹œí–‰ì¼ì") or drf_json.get("ë²•ë ¹", {}).get("ì‹œí–‰ì¼")
        if isinstance(enf, list):
            enf = enf[-1]
        if isinstance(enf, dict):
            enf = enf.get("@ì‹œí–‰ì¼ì") or enf.get("#text")
        enforcement_date = (str(enf).strip() if enf else None) or ""

        if enforcement_date:
            enforcement_date = enforcement_date[:10]  # 'YYYY-MM-DD' í˜•ì‹ ë³´ì •


        if full_text:
            payloads.append({
                "chunk_id": str(uuid.uuid4()), # âœ… uuid ì¶”ê°€
                "law_name": law_name,          # âœ… ì›ë³¸ ë²•ë ¹ëª… ì¶”ê°€
                "law_name_norm": normalize_law_name(law_name),
                "article_number_norm": art_no,
                "text": full_text,
                "enforcement_date": enforcement_date,
            })
    return payloads


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì™¸ë¶€ í´ë¼ì´ì–¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def init_clients():
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY missing in environment")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    engine: Engine = create_engine(f"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}")
    qdrant = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT, timeout=120) # QdrantClient ìƒì„± ì‹œ ëŠë ¤ì§ˆ ê²½ìš° ëŒ€ë¹„ timeout ì¶”ê°€
    return openai_client, engine, qdrant


def ensure_pg_schema(engine: Engine):
    ddl = text(
        """
        CREATE TABLE IF NOT EXISTS law_chunks (
            id SERIAL PRIMARY KEY,
            law_name_norm TEXT NOT NULL,
            article_number_norm TEXT NOT NULL,
            text TEXT NOT NULL,
            enforcement_date TEXT
        );
        CREATE UNIQUE INDEX IF NOT EXISTS idx_law_chunks_unique
            ON law_chunks (law_name_norm, article_number_norm);
        """
    )
    with engine.begin() as conn:
        conn.execute(ddl)


def ensure_qdrant_schema(qdrant: QdrantClient):
    try:
        qdrant.get_collection(COLLECTION)
    except Exception:
        qdrant.recreate_collection(
            collection_name=COLLECTION,
            vectors_config=qmodels.VectorParams(size=EMBED_DIM, distance=qmodels.Distance.COSINE),
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DRF Fetch
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_drf_json(law_name: str) -> dict:
    law_id = LAW_ID_MAP.get(law_name, law_name)
    r = requests.get(
        BASE_URL,
        params={"OC": LAW_OC_ID, "target": "law", "ID": law_id, "type": "JSON"},
        timeout=20,
    )
    r.raise_for_status()
    return r.json()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Upsert to PG & Qdrant
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def upsert_pg(engine: Engine, rows: List[dict]):
    if not rows:
        return
    sql = text(
        """
        INSERT INTO law_chunks (chunk_id, law_name, law_name_norm, article_number_norm, text, enforcement_date)
        VALUES (:chunk_id, :law_name, :law_name_norm, :article_number_norm, :text, :enforcement_date)
        ON CONFLICT (law_name_norm, article_number_norm)
        DO UPDATE SET text = EXCLUDED.text,
                      enforcement_date = EXCLUDED.enforcement_date;
        """
    )
    with engine.begin() as conn:
        conn.execute(sql, rows)



def upsert_qdrant(qdrant: QdrantClient, openai_client: OpenAI, rows: List[dict]):
    if not rows:
        return

    batch_size = 100  # âœ… í•œë²ˆì— ì²˜ë¦¬í•  ë²¡í„° ìˆ˜
    for i in range(0, len(rows), batch_size):
        batch = rows[i:i + batch_size]
        print(f"ğŸ“¤ Qdrant ì—…ë¡œë“œ ì¤‘... {i+1} ~ {i+len(batch)} / {len(rows)}")

        texts = [r["text"] for r in batch]
        embeds = openai_client.embeddings.create(model=EMBED_MODEL, input=texts).data
        vectors = [e.embedding for e in embeds]

        points = []
        for r, vec in zip(batch, vectors):
            pid = int(f"{abs(hash(r['law_name_norm'])) % 10_000}{r['article_number_norm']:0>4}")
            payload = {
                "law_name_norm": r["law_name_norm"],
                "article_number_norm": r["article_number_norm"],
                "text": r["text"],
                "enforcement_date": r["enforcement_date"],
            }
            points.append(qmodels.PointStruct(id=pid, vector=vec, payload=payload))

        qdrant.upsert(collection_name=COLLECTION, points=points)
        time.sleep(0.3)  # ê³¼ë¶€í•˜ ë°©ì§€

    print("âœ… Qdrant ì—…ë¡œë“œ ì™„ë£Œ")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë£¨í‹´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def update_one_law(law_name: str):
    print(f"\nğŸ”„ [Update] {law_name} â€” DRF fetch")
    drf_json = fetch_drf_json(law_name)
    rows = extract_article_payloads(law_name, drf_json)
    if not rows:
        print(f"âš ï¸  {law_name}: ì¶”ì¶œëœ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤(ì¡°ë¬¸ì—¬ë¶€='ì¡°ë¬¸' ì—†ìŒ).")
        return 0

    openai_client, engine, qdrant = init_clients()
    ensure_pg_schema(engine)
    ensure_qdrant_schema(qdrant)

    print(f"ğŸ—„ï¸  PG upsert: {len(rows)} rows")
    upsert_pg(engine, rows)

    print(f"ğŸ§  Qdrant upsert+embed: {len(rows)} points")
    upsert_qdrant(qdrant, openai_client, rows)

    print(f"âœ… ì™„ë£Œ: {law_name} â€” {len(rows)}ê°œ ì¡°ë¬¸ ë™ê¸°í™”")
    return len(rows)


def update_all():
    total = 0
    for law in LAW_ID_MAP.keys():
        try:
            total += update_one_law(law)
        except Exception as e:
            print(f"âŒ {law} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            continue
        time.sleep(0.8)  # API ê³¼í˜¸ì¶œ ë°©ì§€
    print(f"\nğŸ‰ ì „ì²´ ì™„ë£Œ: {total}ê°œ ì¡°ë¬¸ ë™ê¸°í™”")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LLeX DRFâ†’PG/Qdrant ìµœì‹ í™” ë„êµ¬")
    parser.add_argument("--all", action="store_true", help="ëª¨ë“  ë²•ë ¹ ìµœì‹ í™”")
    parser.add_argument("--law", type=str, help="íŠ¹ì • ë²•ë ¹ëª…ë§Œ ìµœì‹ í™” (ì˜ˆ: ì‚°ì—…ì•ˆì „ë³´ê±´ê¸°ì¤€ì—ê´€í•œê·œì¹™)")
    args = parser.parse_args()

    if args.all:
        update_all()
    elif args.law:
        update_one_law(args.law)
    else:
        print("ì‚¬ìš©ë²•: --all ë˜ëŠ” --law 'ë²•ë ¹ëª…'")
