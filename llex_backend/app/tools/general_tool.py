#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
general_tool_v7.0_async (LLeX GPT-5 êµ¬ì¡° ëŒ€ì‘)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Router â†’ ToolPlan â†’ Stream êµ¬ì¡°
- ë¹„ë™ê¸° AsyncOpenAI ìŠ¤íŠ¸ë¦¬ë°
- ToolChunk ê¸°ë°˜ ì‹¤ì‹œê°„ í† í° ì „ì†¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

import os, datetime, asyncio
from openai import AsyncOpenAI
from dotenv import load_dotenv
from core.stream import ToolChunk

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§  ë©”ì¸ ì‹¤í–‰ (ToolChunk ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def run(plan):
    """
    ì¼ë°˜ ëŒ€í™”í˜• Tool (GPT-5 êµ¬ì¡° ëŒ€ì‘)
    - Router â†’ plan.args["query"] ì…ë ¥
    - ToolChunk ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    """
    query = plan.args.get("query", "")
    yield ToolChunk(type="status", payload=f"ğŸ’¬ ì¼ë°˜ ëŒ€í™” ì‹œì‘: {query}")

    system_msg = """ë„ˆëŠ” LinkCampusì˜ ì¬ë‚œÂ·ì•ˆì „ ê´€ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸ LLeX.Aiì•¼.
ë„ˆì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•´, ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ë°˜ì˜í•´
ìì—°ìŠ¤ëŸ½ê³  ì‹¤ë¬´ì— ë„ì›€ì´ ë˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëŒ€ë‹µí•˜ëŠ” ê²ƒì´ì•¼.

ê·œì¹™:
1ï¸âƒ£ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ ë¬¸ë§¥ìƒ ì—°ê²°ëœ ë‹µë³€ì„ í•´.
2ï¸âƒ£ ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ â€œí™•ì¸ í•„ìš”â€ë¼ê³  ë§í•´.
3ï¸âƒ£ ë„ˆë¬´ ì¥í™©í•˜ì§€ ì•Šê²Œ 3~6ì¤„ ì´ë‚´ë¡œ ëŒ€ë‹µí•´.
4ï¸âƒ£ ê°€ëŠ¥í•œ í•œ ì‹¤ë¬´ì Â·ì‚¬ì‹¤ì  ê·¼ê±°ë¥¼ ë“¤ì–´ ì„¤ëª…í•´.
"""

    prompt = f"[ì´ì „ ëŒ€í™” ë° ì§ˆë¬¸]\n{query}"

    try:
        stream = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt},
            ],
            temperature=0.5,
            max_tokens=800,
            stream=True,
        )

        async for chunk in stream:
            delta = chunk.choices[0].delta.content
            if delta:
                yield ToolChunk(type="text", payload=delta)
                await asyncio.sleep(0)

        yield ToolChunk(type="status", payload="âœ… ì¼ë°˜ ëŒ€í™” ì™„ë£Œ")

    except Exception as e:
        yield ToolChunk(type="error", payload=f"âŒ [GeneralTool] ì˜¤ë¥˜: {str(e)}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“… ë‚ ì§œ ë°˜í™˜ (ë³´ì¡° ìœ í‹¸ ê·¸ëŒ€ë¡œ ìœ ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_today_date_tool() -> str:
    """ì˜¤ëŠ˜ ë‚ ì§œë¥¼ 'YYYY-MM-DD' í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    return datetime.date.today().strftime("%Y-%m-%d")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§¹ í…ìŠ¤íŠ¸ ì •ì œ ìœ í‹¸ (ë³´ì¡° ìœ í‹¸ ê·¸ëŒ€ë¡œ ìœ ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text_tool(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ì œ (ì¤„ë°”ê¿ˆ/ê³µë°± ì œê±°)"""
    return " ".join(text.split())
