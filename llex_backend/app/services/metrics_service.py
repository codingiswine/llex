#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
metrics_service.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… MLOps ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- ì‘ë‹µ ì‹œê°„, í† í° ì‚¬ìš©ëŸ‰, ì—ëŸ¬ìœ¨ ì¶”ì 
- Agentë³„ ì‚¬ìš© í†µê³„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
import time
import logging
from typing import Optional, Dict, Any
from datetime import datetime
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from contextlib import asynccontextmanager

logger = logging.getLogger("MetricsService")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“Š Prometheus Metrics ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ìš”ì²­ ì¹´ìš´í„°
request_counter = Counter(
    'llex_requests_total',
    'Total number of requests',
    ['endpoint', 'agent_type', 'status']
)

# ì‘ë‹µ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
response_time_histogram = Histogram(
    'llex_response_time_seconds',
    'Response time in seconds',
    ['endpoint', 'agent_type'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

# í† í° ì‚¬ìš©ëŸ‰
token_usage_counter = Counter(
    'llex_tokens_used_total',
    'Total tokens used',
    ['agent_type', 'model']
)

# ì—ëŸ¬ ì¹´ìš´í„°
error_counter = Counter(
    'llex_errors_total',
    'Total errors',
    ['endpoint', 'error_type']
)

# Agent ì‚¬ìš© ì¹´ìš´í„°
agent_usage_counter = Counter(
    'llex_agent_usage_total',
    'Agent usage count',
    ['agent_type']
)

# ë™ì‹œ í™œì„± ìš”ì²­ ìˆ˜
active_requests_gauge = Gauge(
    'llex_active_requests',
    'Number of active requests',
    ['endpoint']
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¯ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.start_time = time.time()
        self.total_requests = 0
        self.total_errors = 0

    def record_request(self, endpoint: str, agent_type: str, status: str = "success"):
        """ìš”ì²­ ê¸°ë¡"""
        request_counter.labels(endpoint=endpoint, agent_type=agent_type, status=status).inc()
        self.total_requests += 1
        logger.info(f"ğŸ“Š [Metrics] Request recorded: {endpoint} / {agent_type} / {status}")

    def record_response_time(self, endpoint: str, agent_type: str, duration: float):
        """ì‘ë‹µ ì‹œê°„ ê¸°ë¡"""
        response_time_histogram.labels(endpoint=endpoint, agent_type=agent_type).observe(duration)
        logger.info(f"â±ï¸ [Metrics] Response time: {duration:.2f}s ({endpoint}/{agent_type})")

    def record_token_usage(self, agent_type: str, model: str, tokens: int):
        """í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        token_usage_counter.labels(agent_type=agent_type, model=model).inc(tokens)
        logger.info(f"ğŸ« [Metrics] Token usage: {tokens} ({agent_type}/{model})")

    def record_error(self, endpoint: str, error_type: str):
        """ì—ëŸ¬ ê¸°ë¡"""
        error_counter.labels(endpoint=endpoint, error_type=error_type).inc()
        self.total_errors += 1
        logger.error(f"âŒ [Metrics] Error recorded: {endpoint} / {error_type}")

    def record_agent_usage(self, agent_type: str):
        """Agent ì‚¬ìš© ê¸°ë¡"""
        agent_usage_counter.labels(agent_type=agent_type).inc()
        logger.info(f"ğŸ¤– [Metrics] Agent used: {agent_type}")

    @asynccontextmanager
    async def track_request(self, endpoint: str, agent_type: str = "unknown"):
        """ìš”ì²­ ì¶”ì  ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        active_requests_gauge.labels(endpoint=endpoint).inc()
        start_time = time.time()

        try:
            yield
            duration = time.time() - start_time
            self.record_response_time(endpoint, agent_type, duration)
            self.record_request(endpoint, agent_type, "success")
        except Exception as e:
            duration = time.time() - start_time
            self.record_response_time(endpoint, agent_type, duration)
            self.record_request(endpoint, agent_type, "error")
            self.record_error(endpoint, type(e).__name__)
            raise
        finally:
            active_requests_gauge.labels(endpoint=endpoint).dec()

    def get_summary(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ ì •ë³´"""
        uptime = time.time() - self.start_time
        return {
            "uptime_seconds": uptime,
            "total_requests": self.total_requests,
            "total_errors": self.total_errors,
            "error_rate": self.total_errors / max(self.total_requests, 1),
            "timestamp": datetime.now().isoformat()
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ Global Metrics Collector
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
metrics_collector = MetricsCollector()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“ˆ Prometheus ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_prometheus_metrics():
    """Prometheus ë©”íŠ¸ë¦­ ë°˜í™˜"""
    return generate_latest()


__all__ = [
    "metrics_collector",
    "get_prometheus_metrics",
    "MetricsCollector",
    "CONTENT_TYPE_LATEST"
]

print("âœ… [init] metrics_service.py ë¡œë“œ ì™„ë£Œ")
