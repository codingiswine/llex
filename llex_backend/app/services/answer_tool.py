#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
answer_tool.py (LLeX v3.0)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ëª©ì :
    - ì§ˆë¬¸ ìœ í˜•ë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬
    - ë²•ë ¹(RAG)ì€ "ì„¤ëª… + ì¡°ë¬¸ ì›ë¬¸" 2ë‹¨ êµ¬ì¡°
    - ì¼ë°˜/ì›¹/DBëŠ” ê¸°ì¡´ Perplexity ìŠ¤íƒ€ì¼ ìœ ì§€
"""

import re
import asyncio
import datetime
from typing import Optional, Dict, Any
from openai import OpenAI
from openai import OpenAIError
from app.config import settings


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ ì´ˆê¸° ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
client = OpenAI(api_key=settings.OPENAI_API_KEY)
LOG_PATH = "logs/answer_history.log"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”— í•˜ì´í¼ë§í¬ ë³€í™˜ ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_law_link(text: str) -> str:
    """'ã€Œë²•ë ¹ëª…ã€ ì œnì¡°' â†’ ë§í¬ ìë™ ë³€í™˜"""
    pattern = r'ã€Œ(.+?)ã€\s*ì œ(\d+)ì¡°'
    def _repl(match: re.Match) -> str:
        law_name, article = match.groups()
        law_clean = law_name.replace(" ", "")
        link = f"https://www.law.go.kr/ë²•ë ¹/{law_clean}/ì œ{article}ì¡°"
        return f"[{match.group(0)}]({link})"
    return re.sub(pattern, _repl, text)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸªµ ë¡œê¹… ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_answer(query: str, context_type: str, answer: str) -> None:
    """ì§ˆë¬¸Â·ë‹µë³€ ë¡œê·¸ ì €ì¥"""
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(f"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] ({context_type})\n")
            f.write(f"Q: {query}\nA: {answer}\n{'-'*60}\n")
    except Exception:
        pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ§  AnswerTool í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AnswerTool:
    """ë²•ë ¹/ì›¹/DB/ì¼ë°˜ ì§ˆë¬¸ í†µí•© ë‹µë³€ ìƒì„±ê¸°"""

    def __init__(self, model: str = "gpt-4o"):
        self.model = model
        self.client = client

    # -----------------------------
    # ğŸ§© ì¼ë°˜/ì›¹/DBìš© í”„ë¡¬í”„íŠ¸
    # -----------------------------
    def _build_general_prompt(self, query: str, context: str, context_type: str) -> str:
        return f"""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ì¬ë‚œÂ·ì•ˆì „Â·ì†Œë°© ê´€ë ¨ ë²•ë ¹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ì§ˆë¬¸ê³¼ ì°¸ê³ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ë²•ì  ê·¼ê±°ì™€ êµ¬ì²´ì  ìˆ˜ì¹˜ ê¸°ì¤€**ì„ í¬í•¨í•´ ë‹µë³€í•˜ì„¸ìš”.

        [ì§ˆë¬¸]
        {query}

        [ê²€ìƒ‰ê²°ê³¼ìœ í˜•]
        {context_type}

        [ì°¸ê³ ìë£Œ]
        {context or 'ê´€ë ¨ ìë£Œ ì—†ìŒ'}

        ---
        âš™ï¸ ë‹µë³€ ì‘ì„± ê·œì¹™
        1ï¸âƒ£ **ê²°ë¡  â†’ ìˆ˜ì¹˜ ê¸°ì¤€ â†’ ë²•ì  ê·¼ê±° â†’ ì„¤ëª…** ìˆœì„œë¡œ ì‘ì„±
        2ï¸âƒ£ ë²•ë ¹ì€ ã€Œë²•ë ¹ëª… ì œnì¡°ã€ í˜•ì‹ìœ¼ë¡œ ì¸ìš©í•˜ê³  í•˜ì´í¼ë§í¬ë¡œ ì—°ê²°
        3ï¸âƒ£ ìˆ˜ì¹˜(ì˜ˆ: 20m, 30m, 100ã¡, 6ê°œì›” ë“±)ëŠ” ëª…í™•íˆ í‘œì‹œ
        4ï¸âƒ£ ì›¹ ìë£Œë§Œ ìˆì„ ê²½ìš° "ë²•ë ¹ ê·¼ê±° ì—†ìŒ" ëª…ì‹œ
        5ï¸âƒ£ ì‚¬ì‹¤ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±, ì¶”ì¸¡ì„± ë¬¸ì¥ ê¸ˆì§€
        6ï¸âƒ£ ë§ˆì§€ë§‰ ì¤„ì— "[ì‚¬ìš©ëœ ë„êµ¬: {context_type}]" ì¶”ê°€
        """

    # -----------------------------
    # âš–ï¸ ë²•ë ¹ìš© í”„ë¡¬í”„íŠ¸
    # -----------------------------
    def _build_law_prompt(self, query: str, law_context: str) -> str:
        return f"""
        ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ë²•ë ¹ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
        ì‚¬ìš©ìê°€ íŠ¹ì • ë²•ë ¹(ì˜ˆ: 'ì‚°ì—…ì•ˆì „ë³´ê±´ë²• ì œ22ì¡°')ì„ ë¬¼ì–´ë³´ë©´ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë‹µë³€í•´.

        ğŸ“˜ ì¶œë ¥ í˜•ì‹ (Markdown)
        1ï¸âƒ£ **ë²•ë ¹ ì„¤ëª… ìš”ì•½**
        - í•´ë‹¹ ì¡°í•­ì˜ ëª©ì , ì˜ë¯¸, ì‹¤ë¬´ìƒ í•´ì„ì„ ê°„ê²°íˆ ì„¤ëª…
        - í•„ìš” ì‹œ ë²•ì  ì˜ë¬´, ì ìš© ë²”ìœ„ ì–¸ê¸‰

        2ï¸âƒ£ **ì¡°ë¬¸ ì›ë¬¸ ì „ì²´**
        - ë°˜ë“œì‹œ ì•„ë˜ ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤Œ (ë¬¸ì¥ ìˆ˜ì • ê¸ˆì§€)
        - ì¤„ë°”ê¿ˆ, ë²ˆí˜¸ ë“± í˜•ì‹ì„ ìœ ì§€

        [ì‚¬ìš©ì ì§ˆë¬¸]
        {query}

        [ë²•ë ¹ ì›ë¬¸]
        {law_context}
        """

    # -----------------------------
    # ğŸ”® GPT í˜¸ì¶œ
    # -----------------------------
    def _generate_answer(self, prompt: str) -> str:
        try:
            res = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1800,
            )
            return make_law_link(res.choices[0].message.content.strip())
        except OpenAIError as e:
            return f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    # -----------------------------
    # ğŸ§  í†µí•© ì‹¤í–‰
    # -----------------------------
    def run(
        self,
        query: str,
        law_context: Optional[str] = None,
        web_summary: Optional[str] = None,
        db_context: Optional[str] = None,
    ) -> str:
        if law_context:
            context_type, prompt = "law_rag", self._build_law_prompt(query, law_context)
        elif web_summary:
            context_type, prompt = "websearch", self._build_general_prompt(query, web_summary, "ì›¹ê²€ìƒ‰ ê¸°ë°˜")
        elif db_context:
            context_type, prompt = "db_query", self._build_general_prompt(query, db_context, "DB ê¸°ë°˜")
        else:
            context_type, prompt = "general", self._build_general_prompt(query, "", "ì¼ë°˜")

        answer = self._generate_answer(prompt)
        log_answer(query, context_type, answer)
        return answer

    async def run_async(self, *args, **kwargs):
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.run, *args, **kwargs)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸŒ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
answer_tool = AnswerTool()
